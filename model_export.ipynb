{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"./cursus-e1_model/ATLDSD4/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/thomas/Documents/learn/comp-sci/cursus-e1/cursus-e1_model/Download/images/als0.jpeg: 256x256 4 gray_spots, 1 healthy_leaf, 8.1ms\n",
      "Speed: 0.2ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 256, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{ '_keys': ('boxes', 'masks', 'probs'),\n",
       "   'boxes': ultralytics.yolo.engine.results.Boxes\n",
       " type:  torch.Tensor\n",
       " shape: torch.Size([5, 6])\n",
       " dtype: torch.float32\n",
       " tensor([[ 16.73875,  36.96724, 139.76279, 223.52263,   0.94935,   4.00000],\n",
       "         [ 49.05594, 184.30782,  61.97062, 198.10686,   0.57931,   2.00000],\n",
       "         [ 76.87514,  54.76832,  86.58108,  61.74348,   0.57199,   2.00000],\n",
       "         [ 20.94683, 129.28436,  62.22750, 163.38625,   0.28678,   2.00000],\n",
       "         [ 34.07173,  43.49267,  58.03317,  59.08204,   0.26470,   2.00000]], device='cuda:0'),\n",
       "   'masks': ultralytics.yolo.engine.results.Masks\n",
       " type:  torch.Tensor\n",
       " shape: torch.Size([5, 256, 256])\n",
       " dtype: torch.float32\n",
       " tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0'),\n",
       "   'names': {0: 'alternaria_leaf_spot', 1: 'brown_spot', 2: 'gray_spot', 3: 'rust', 4: 'healthy_leaf'},\n",
       "   'orig_img': array([[[  3,  30,  26],\n",
       "         [  4,  31,  27],\n",
       "         [ 10,  33,  29],\n",
       "         ...,\n",
       "         [123, 143, 120],\n",
       "         [112, 132, 109],\n",
       "         [ 72,  92,  69]],\n",
       " \n",
       "        [[  4,  29,  25],\n",
       "         [  6,  31,  27],\n",
       "         [ 10,  33,  29],\n",
       "         ...,\n",
       "         [130, 152, 128],\n",
       "         [127, 147, 124],\n",
       "         [ 85, 107,  83]],\n",
       " \n",
       "        [[  5,  28,  24],\n",
       "         [  6,  29,  25],\n",
       "         [  9,  30,  27],\n",
       "         ...,\n",
       "         [113, 136, 114],\n",
       "         [115, 136, 114],\n",
       "         [ 78, 101,  79]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 44,  93,  77],\n",
       "         [ 40,  89,  73],\n",
       "         [ 36,  83,  67],\n",
       "         ...,\n",
       "         [ 44,  51,  71],\n",
       "         [ 45,  52,  72],\n",
       "         [ 45,  52,  72]],\n",
       " \n",
       "        [[ 43,  92,  76],\n",
       "         [ 40,  89,  73],\n",
       "         [ 36,  85,  69],\n",
       "         ...,\n",
       "         [ 40,  47,  67],\n",
       "         [ 41,  48,  68],\n",
       "         [ 41,  48,  68]],\n",
       " \n",
       "        [[ 42,  91,  75],\n",
       "         [ 40,  89,  73],\n",
       "         [ 37,  86,  70],\n",
       "         ...,\n",
       "         [ 37,  44,  64],\n",
       "         [ 38,  45,  65],\n",
       "         [ 38,  45,  65]]], dtype=uint8),\n",
       "   'orig_shape': (236, 214),\n",
       "   'path': '/home/thomas/Documents/learn/comp-sci/cursus-e1/cursus-e1_model/Download/images/als0.jpeg',\n",
       "   'probs': None,\n",
       "   'speed': {'inference': 8.091449737548828, 'postprocess': 1.771688461303711, 'preprocess': 0.232696533203125}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(source='./Download/images/als0.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.54 ðŸš€ Python-3.10.10 torch-2.0.0+cu117 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from cursus-e1_model/ATLDSD4/weights/best.pt with input shape (1, 3, 256, 256) BCHW and output shape(s) ((1, 41, 1344), (1, 32, 64, 64)) (6.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.1...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 0.6s, saved as cursus-e1_model/ATLDSD4/weights/best.onnx (12.5 MB)\n",
      "\n",
      "Export complete (0.7s)\n",
      "Results saved to \u001b[1m/home/thomas/Documents/learn/comp-sci/cursus-e1/cursus-e1_model/cursus-e1_model/ATLDSD4/weights\u001b[0m\n",
      "Predict:         yolo predict task=segment model=cursus-e1_model/ATLDSD4/weights/best.onnx imgsz=256 \n",
      "Validate:        yolo val task=segment model=cursus-e1_model/ATLDSD4/weights/best.onnx imgsz=256 data=./data/YOLO_Format/ATLDSD.yaml \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.0+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cursus-e1_model/ATLDSD4/weights/best.onnx'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.export(format='onnx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model-MZNk3tvk-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63185a3d010c916f99d3b3929ce14e09dfd2ea2f625bcdc8eee6c164650fa57a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
